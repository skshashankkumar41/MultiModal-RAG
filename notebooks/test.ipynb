{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "257752db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17999981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['page_2.png',\n",
       " 'page_3.png',\n",
       " 'page_1.png',\n",
       " 'page_4.png',\n",
       " '.DS_Store',\n",
       " 'page_5.png',\n",
       " 'page_7.png',\n",
       " 'page_6.png',\n",
       " 'page_10.png',\n",
       " 'page_11.png',\n",
       " 'page_12.png',\n",
       " 'page_8.png',\n",
       " 'page_9.png']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/Users/shashanksrivastava/Desktop/sks/technomile/data/pdf/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f34a70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('LLaMA: Open and Efﬁcient Foundation Language Models Hugo Touvron∗, Thibaut Lavril∗, Gautier Izacard∗, Xavier Martinet Marie-Anne Lachaux, Timothee Lacroix, Baptiste Rozière')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ccc534",
   "metadata": {},
   "outputs": [],
   "source": [
    " def pipeline_v1_persist(self):\n",
    "        '''\n",
    "        Seperate indexes for text and image and will utilize seperate index for query as well\n",
    "        '''\n",
    "        client = qdrant_client.QdrantClient(path=\"./data/index\")\n",
    "        text_store = self._create_vector_stores(client=client, collection_name='text_collection_v1')\n",
    "        image_store = self._create_vector_stores(client=client, collection_name='image_collection_v1')\n",
    "        \n",
    "        storage_context = self._create_storage_context(text_store, image_store)\n",
    "        \n",
    "        text_documents = self._return_text_documents()\n",
    "        img_documents = self._return_img_documents()\n",
    "\n",
    "        \n",
    "        _ = MultiModalVectorStoreIndex(text_documents, storage_context=storage_context, embed_model=self.embed_model,image_embed_model=self.image_embed_model)\n",
    "        _ = MultiModalVectorStoreIndex(img_documents, storage_context=storage_context, embed_model=self.embed_model, image_embed_model=self.image_embed_model)\n",
    "        \n",
    "        client.close()\n",
    "        \n",
    "        return None \n",
    "    \n",
    "def query_engine_v1(self, query):\n",
    "        client = qdrant_client.QdrantClient(path=\"./data/index\")\n",
    "        \n",
    "        text_store = self._create_vector_stores(client=client, collection_name='text_collection_v1')\n",
    "        image_store = self._create_vector_stores(client=client, collection_name='image_collection_v1')\n",
    "                        \n",
    "        text_index = MultiModalVectorStoreIndex.from_vector_store(\n",
    "            vector_store=text_store,\n",
    "            embed_model=self.embed_model,\n",
    "        )\n",
    "        \n",
    "        img_index = MultiModalVectorStoreIndex.from_vector_store(\n",
    "            vector_store=image_store,\n",
    "            embed_model=self.image_embed_model,\n",
    "        )\n",
    "        \n",
    "        text_retriever = text_index.as_retriever(similarity_top_k=3)\n",
    "        text_retrieval_results = text_retriever.retrieve(query)\n",
    "        \n",
    "        img_retriever = img_index.as_retriever(image_similarity_top_k=3)\n",
    "        img_retrieval_results = img_retriever.retrieve(query)\n",
    "        \n",
    "        retrieved_texts = [doc.node.text for doc in text_retrieval_results]\n",
    "        retrieved_images = [doc.node.metadata.get('file_path') for doc in img_retrieval_results]\n",
    "        \n",
    "        print(\"text_retrieval_results:::\",retrieved_texts)       \n",
    "        print(\"img_retrieval_results:::\",retrieved_images) \n",
    "        \n",
    "        client.close()\n",
    "        \n",
    "        return retrieved_texts, retrieved_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c897e18e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea301717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting easyocr\n",
      "  Using cached easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (10.2.0)\n",
      "Collecting scikit-image\n",
      "  Using cached scikit_image-0.24.0-cp39-cp39-macosx_10_9_x86_64.whl (14.1 MB)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (2.2.1)\n",
      "Requirement already satisfied: PyYAML in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (6.0.1)\n",
      "Collecting Shapely\n",
      "  Using cached shapely-2.0.5-cp39-cp39-macosx_10_9_x86_64.whl (1.5 MB)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (1.12.0)\n",
      "Requirement already satisfied: torchvision>=0.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (0.17.1)\n",
      "Collecting python-bidi\n",
      "  Using cached python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
      "Collecting pyclipper\n",
      "  Using cached pyclipper-1.3.0.post5-cp39-cp39-macosx_10_9_x86_64.whl (146 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from easyocr) (1.26.4)\n",
      "Collecting ninja\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-macosx_10_9_universal2.macosx_10_9_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl (270 kB)\n",
      "Collecting opencv-python-headless\n",
      "  Using cached opencv-python-headless-4.10.0.84.tar.gz (95.1 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch->easyocr) (2024.3.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch->easyocr) (3.13.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch->easyocr) (3.1.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch->easyocr) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch->easyocr) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch->easyocr) (1.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jinja2->torch->easyocr) (2.1.5)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from python-bidi->easyocr) (1.16.0)\n",
      "Collecting imageio>=2.33\n",
      "  Using cached imageio-2.34.2-py3-none-any.whl (313 kB)\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Using cached tifffile-2024.7.2-py3-none-any.whl (225 kB)\n",
      "Collecting lazy-loader>=0.4\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging>=21 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-image->easyocr) (23.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sympy->torch->easyocr) (1.3.0)\n",
      "Building wheels for collected packages: opencv-python-headless\n",
      "  Building wheel for opencv-python-headless (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for opencv-python-headless: filename=opencv_python_headless-4.10.0.84-cp39-cp39-macosx_10_16_x86_64.whl size=27382440 sha256=437726432c072735597495b94a2e532b335e5d8a888307c1c0c09095dde4e513\n",
      "  Stored in directory: /Users/shashanksrivastava/Library/Caches/pip/wheels/b2/ff/73/e8dc60d0234fc732638efc4d8f7b21bc00d106693ee82e0b36\n",
      "Successfully built opencv-python-headless\n",
      "Installing collected packages: tifffile, lazy-loader, imageio, Shapely, scikit-image, python-bidi, pyclipper, opencv-python-headless, ninja, easyocr\n",
      "Successfully installed Shapely-2.0.5 easyocr-1.7.1 imageio-2.34.2 lazy-loader-0.4 ninja-1.11.1.1 opencv-python-headless-4.10.0.84 pyclipper-1.3.0.post5 python-bidi-0.4.2 scikit-image-0.24.0 tifffile-2024.7.2\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe9cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    # Initialize the reader with the desired languages\n",
    "    reader = easyocr.Reader(['en'])  # You can add more languages like ['en', 'es', 'fr']\n",
    "    \n",
    "    # Perform OCR on the image\n",
    "    result = reader.readtext(image_path)\n",
    "    \n",
    "    # Extract text from the result\n",
    "    text = ' '.join([item[1] for item in result])\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "\n",
    "image_path = '/Users/shashanksrivastava/Desktop/sks/technomile/data/table_images/llama.pdf_page_7_0.png'  # Update this with your image path\n",
    "extracted_text = extract_text_from_image(image_path)\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f20b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def persist():\n",
    "    client = qdrant_client.QdrantClient(path=\"./data/index\")\n",
    "    \n",
    "    \n",
    "    text_store = QdrantVectorStore(\n",
    "                    client=client, collection_name='text_collection'\n",
    "                    )\n",
    "    image_store = QdrantVectorStore(\n",
    "        client=client, collection_name=\"image_collection\"\n",
    "    )\n",
    "    # embed_model = HuggingFaceEmbedding('openai/clip-vit-large-patch14')\n",
    "    storage_context = StorageContext.from_defaults(vector_store=text_store, image_store=image_store)\n",
    "    service_context = ServiceContext.from_defaults(llm=None, embed_model=ClipEmbedding(model_name='ViT-L/14',embed_batch_size=16))\n",
    "    # service_context = ServiceContext.from_defaults(llm=None, embed_model=embed_model)\n",
    "    \n",
    "    text_documents = SimpleDirectoryReader('./data/pdf').load_data()\n",
    "    img_documets = SimpleDirectoryReader('./data/table_images').load_data()\n",
    "    \n",
    "\n",
    "    node_parser = SentenceSplitter(chunk_size=100, chunk_overlap=20)\n",
    "    nodes = node_parser.get_nodes_from_documents(text_documents)\n",
    "        \n",
    "    print(\"text documents loaded:\", len(text_documents))\n",
    "    print(\"len nodes:\",len(nodes))\n",
    "    print(\"immage documents loaded:\", len(img_documets))\n",
    "    # print(\"nodes:\",nodes)\n",
    "    \n",
    "    index = MultiModalVectorStoreIndex(nodes+img_documets, storage_context=storage_context, service_context=service_context)\n",
    "    \n",
    "    query = 'compare palm and llama'\n",
    "    \n",
    "    retriever = index.as_retriever(image_similarity_top_k=3)\n",
    "    retrieval_results = retriever.retrieve(query)\n",
    "    \n",
    "    retrieved_image = []\n",
    "    for res_node in retrieval_results:\n",
    "        print('\\n Node:',res_node.metadata)\n",
    "        if isinstance(res_node.node, ImageNode):\n",
    "            retrieved_image.append(res_node.node.metadata[\"file_path\"])\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "    print('images:',retrieved_image)\n",
    "    \n",
    "# persist()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb53b1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f908da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Structure for /Users/shashanksrivastava/Desktop/sks/technomile:\n",
      "├── .DS_Store\n",
      "├── app.py\n",
      "├── data\n",
      "│   ├── .DS_Store\n",
      "│   ├── images\n",
      "│   │   ├── llama.pdf_page_1.png\n",
      "│   │   ├── llama.pdf_page_10.png\n",
      "│   │   ├── llama.pdf_page_11.png\n",
      "│   │   ├── llama.pdf_page_12.png\n",
      "│   │   ├── llama.pdf_page_2.png\n",
      "│   │   ├── llama.pdf_page_3.png\n",
      "│   │   ├── llama.pdf_page_4.png\n",
      "│   │   ├── llama.pdf_page_5.png\n",
      "│   │   ├── llama.pdf_page_6.png\n",
      "│   │   ├── llama.pdf_page_7.png\n",
      "│   │   ├── llama.pdf_page_8.png\n",
      "│   │   ├── llama.pdf_page_9.png\n",
      "│   ├── index\n",
      "│   │   ├── .lock\n",
      "│   │   ├── collection\n",
      "│   │   │   ├── image_collection_v1\n",
      "│   │   │   │   ├── storage.sqlite\n",
      "│   │   │   ├── image_collection_v3\n",
      "│   │   │   │   ├── storage.sqlite\n",
      "│   │   │   ├── text_collection_v1\n",
      "│   │   │   │   ├── storage.sqlite\n",
      "│   │   │   ├── text_collection_v3\n",
      "│   │   │   │   ├── storage.sqlite\n",
      "│   │   ├── meta.json\n",
      "│   ├── pdf\n",
      "│   │   ├── .DS_Store\n",
      "│   │   ├── llama.pdf\n",
      "│   ├── table_images\n",
      "│   │   ├── llama.pdf_page_10_0.png\n",
      "│   │   ├── llama.pdf_page_10_1.png\n",
      "│   │   ├── llama.pdf_page_11_0.png\n",
      "│   │   ├── llama.pdf_page_12_0.png\n",
      "│   │   ├── llama.pdf_page_1_0.png\n",
      "│   │   ├── llama.pdf_page_2_0.png\n",
      "│   │   ├── llama.pdf_page_3_0.png\n",
      "│   │   ├── llama.pdf_page_4_0.png\n",
      "│   │   ├── llama.pdf_page_4_1.png\n",
      "│   │   ├── llama.pdf_page_5_0.png\n",
      "│   │   ├── llama.pdf_page_5_1.png\n",
      "│   │   ├── llama.pdf_page_6_0.png\n",
      "│   │   ├── llama.pdf_page_6_1.png\n",
      "│   │   ├── llama.pdf_page_7_0.png\n",
      "│   │   ├── llama.pdf_page_7_1.png\n",
      "│   │   ├── llama.pdf_page_8_0.png\n",
      "│   │   ├── llama.pdf_page_9_0.png\n",
      "├── logging.log\n",
      "├── notebooks\n",
      "│   ├── .ipynb_checkpoints\n",
      "│   │   ├── test-checkpoint.ipynb\n",
      "│   ├── test.ipynb\n",
      "├── src\n",
      "│   ├── llama_handler\n",
      "│   │   ├── __pycache__\n",
      "│   │   │   ├── llama_handler.cpython-39.pyc\n",
      "│   │   ├── llama_handler.py\n",
      "│   ├── pdf_handler\n",
      "│   │   ├── __pycache__\n",
      "│   │   │   ├── pdf_handler.cpython-39.pyc\n",
      "│   │   ├── pdf_handler.py\n",
      "│   ├── prompts\n",
      "│   │   ├── __pycache__\n",
      "│   │   │   ├── prompts.cpython-39.pyc\n",
      "│   │   ├── prompts.py\n",
      "│   ├── utils\n",
      "│   │   ├── __pycache__\n",
      "│   │   │   ├── llama_utils.cpython-39.pyc\n",
      "│   │   │   ├── table_transformer.cpython-39.pyc\n",
      "│   │   │   ├── utils.cpython-39.pyc\n",
      "│   │   ├── table_transformer.py\n",
      "│   │   ├── utils.py\n",
      "├── static\n",
      "│   ├── styles.css\n",
      "├── templates\n",
      "│   ├── index.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def print_project_structure(base_path):\n",
    "    # Ensure the base path exists\n",
    "    if not os.path.exists(base_path):\n",
    "        print(f\"Path '{base_path}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Project Structure for {base_path}:\")\n",
    "    print_structure(base_path, \"\")\n",
    "\n",
    "def print_structure(base_path, indent):\n",
    "    # Get list of files and directories in the current path\n",
    "    items = os.listdir(base_path)\n",
    "    \n",
    "    # Iterate over each item\n",
    "    for item in sorted(items):\n",
    "        # Construct full path to the item\n",
    "        item_path = os.path.join(base_path, item)\n",
    "        \n",
    "        # Print item name with proper indentation\n",
    "        print(indent + \"├── \" + item)\n",
    "        \n",
    "        # If item is a directory, recursively print its structure\n",
    "        if os.path.isdir(item_path):\n",
    "            print_structure(item_path, indent + \"│   \")\n",
    "        # (Optional) If item is a symbolic link, you may want to handle it differently\n",
    "        # elif os.path.islink(item_path):\n",
    "        #     link_target = os.readlink(item_path)\n",
    "        #     print(indent + \"└── \" + item + \" -> \" + link_target)\n",
    "\n",
    "# Example usage:\n",
    "base_path = \"/Users/shashanksrivastava/Desktop/sks/technomile\"\n",
    "print_project_structure(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3907e01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9dfc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d44f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4094c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import fitz\n",
    "from PIL import Image\n",
    "import logging\n",
    "from src.utils.table_transformer import detect_and_crop_save_table\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class PdfHandler():\n",
    "    def __init__(self, base_path='./data'):\n",
    "        self.base_path = base_path\n",
    "     \n",
    "    def _list_pdf_files(self):\n",
    "        pdf_files = []\n",
    "        pdf_folder_path = os.path.join(self.base_path, 'pdf')\n",
    "        for root, dirs, files in os.walk(pdf_folder_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".pdf\"):\n",
    "                    pdf_files.append(os.path.join(root, file))\n",
    "        return pdf_files\n",
    "    \n",
    "    def _get_pdf_filename(self, pdf_path):\n",
    "        return os.path.basename(pdf_path)\n",
    "    \n",
    "    def _delete_folders(self):\n",
    "        try:\n",
    "            paths = ['./data/images', './data/table_images']\n",
    "            for path in paths:\n",
    "                if os.path.exists(path):\n",
    "                    os.rmdir(path)\n",
    "                    print(f\"Directory '{path}' successfully removed.\")\n",
    "        except OSError as e:\n",
    "            # Handle potential errors\n",
    "            print(f\"Error: {path} : {e.strerror}\")\n",
    "        \n",
    "    def _convert_pdf_to_image(self):\n",
    "        print(\"Converting PDF pages to images\")\n",
    "        for pdf_path in self._list_pdf_files():\n",
    "            pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "\n",
    "            for page_number in range(pdf_document.page_count):\n",
    "                # Get the page\n",
    "                page = pdf_document[page_number]\n",
    "\n",
    "                # Convert the page to an image\n",
    "                pix = page.get_pixmap()\n",
    "\n",
    "                # Create a Pillow Image object from the pixmap\n",
    "                image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "                \n",
    "                image_output_folder = f\"{self.base_path}/images/\"\n",
    "                \n",
    "                if not os.path.exists(image_output_folder):\n",
    "                    os.makedirs(image_output_folder)\n",
    "\n",
    "                # Save the image\n",
    "                image.save(f\"{image_output_folder}/{self._get_pdf_filename(pdf_path)}_page_{page_number + 1}.png\")\n",
    "\n",
    "            # Close the PDF file\n",
    "            pdf_document.close()\n",
    "            \n",
    "    def _extract_tables_from_images(self):\n",
    "        print(\"Extracting tables from images\")\n",
    "        for file_name in os.listdir(os.path.join(self.base_path,'images')):\n",
    "            if 'png' in file_name:\n",
    "                file_path = os.path.join(self.base_path, 'images' ,file_name)\n",
    "                detect_and_crop_save_table(file_path, cropped_table_directory=os.path.join(self.base_path,'table_images/'))\n",
    "                \n",
    "    def process_pdfs(self):\n",
    "        print(\"Processing PDFs\")\n",
    "        self._delete_folders()\n",
    "        self._convert_pdf_to_image()\n",
    "        self._extract_tables_from_images()\n",
    "        \n",
    "        \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75939ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd23b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5600119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f057a47f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e167019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c904f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
